import os
import pandas as pd
import re
from github import Github
from itertools import cycle
from dotenv import load_dotenv
import time
from urllib.parse import urlparse
from collections import deque
import json

load_dotenv()

TOKENS = [
    os.getenv("GITHUB_TOKEN_DH"),
    os.getenv("GITHUB_TOKEN_GN"),
    os.getenv("GITHUB_TOKEN_HJ"),
    os.getenv("GITHUB_TOKEN_SH"),
    os.getenv("GITHUB_TOKEN_SI")
]

if not all(TOKENS):
    raise ValueError("ëª¨ë“  í† í°ì´ .env íŒŒì¼ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

token_cycle = cycle(TOKENS)

# ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
base_dir = "all_dependencies_tree"
os.makedirs(base_dir, exist_ok=True)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬
processed_repos = set()
failed_repos = set()
dependency_graph = {}  # ì˜ì¡´ì„± ê·¸ë˜í”„ ì €ì¥
stats = {
    'total_repos': 0,
    'successful_downloads': 0,
    'failed_downloads': 0,
    'dependencies_found': 0,
    'start_time': None,
    'end_time': None
}


def get_github_instance():
    return Github(next(token_cycle))


def extract_repo_info(github_url):
    """GitHub URLì—ì„œ owner/repo ì •ë³´ ì¶”ì¶œ"""
    if github_url.endswith('.git'):
        github_url = github_url[:-4]

    parsed = urlparse(github_url)
    path_parts = parsed.path.strip('/').split('/')
    if len(path_parts) >= 2:
        owner = path_parts[0]
        repo = path_parts[1]
        return owner, repo
    return None, None


def get_default_branch(repository):
    """ë¦¬í¬ì§€í† ë¦¬ì˜ ê¸°ë³¸ ë¸Œëœì¹˜ í™•ì¸"""
    try:
        return repository.default_branch
    except:
        return None


def extract_dependencies_from_content(content):
    """Package.swift ë‚´ìš©ì—ì„œ dependencies ì¶”ì¶œ (ë‹¤ì–‘í•œ ë²„ì „ ì œì•½ ì¡°ê±´ í¬í•¨)"""
    dependencies = []

    # dependencies ì„¹ì…˜ ì°¾ê¸°
    dependencies_pattern = r'dependencies:\s*\[(.*?)\]'
    match = re.search(dependencies_pattern, content, re.DOTALL)

    if match:
        deps_content = match.group(1)

        # ë‹¤ì–‘í•œ .package íŒ¨í„´ë“¤ ì°¾ê¸°
        package_patterns = [
            # ê¸°ë³¸ íŒ¨í„´: .package(url: "...", ...)
            r'\.package\s*\(\s*url:\s*["\']([^"\']+)["\'][^)]*\)',
            # ì¶•ì•½ íŒ¨í„´: .package("...", ...)
            r'\.package\s*\(\s*["\']([^"\']+)["\'][^)]*\)',
        ]

        found_urls = set()  # ì¤‘ë³µ ì œê±°

        for pattern in package_patterns:
            urls = re.findall(pattern, deps_content)
            for url in urls:
                if 'github.com' in url:
                    found_urls.add(url)

        dependencies = list(found_urls)

        # ë²„ì „ ì •ë³´ë„ í•¨ê»˜ ì¶”ì¶œ (ë¶„ì„ìš©)
        if dependencies:
            print(f"    ğŸ” ë°œê²¬ëœ ì˜ì¡´ì„± íŒ¨í„´ë“¤:")

            # .package ì „ì²´ êµ¬ë¬¸ë“¤ ì°¾ê¸°
            full_package_pattern = r'\.package\s*\([^)]+\)'
            package_declarations = re.findall(full_package_pattern, deps_content, re.DOTALL)

            for i, decl in enumerate(package_declarations, 1):
                # URL ì¶”ì¶œ
                url_match = re.search(r'url:\s*["\']([^"\']+)["\']|["\']([^"\']+)["\']', decl)
                if url_match:
                    url = url_match.group(1) or url_match.group(2)
                    if 'github.com' in url:
                        # ë²„ì „ ì œì•½ ì¡°ê±´ ë¶„ì„
                        version_info = analyze_version_constraint(decl)
                        print(f"      {i}. {url}")
                        if version_info:
                            print(f"         â””â”€ ë²„ì „: {version_info}")

    return dependencies


def analyze_version_constraint(package_declaration):
    """Package ì„ ì–¸ì—ì„œ ë²„ì „ ì œì•½ ì¡°ê±´ ë¶„ì„"""
    version_patterns = {
        'from': r'from:\s*["\']([^"\']+)["\']',
        'upToNextMajor': r'\.upToNextMajor\s*\(\s*from:\s*["\']([^"\']+)["\']\s*\)',
        'upToNextMinor': r'\.upToNextMinor\s*\(\s*from:\s*["\']([^"\']+)["\']\s*\)',
        'exact': r'\.exact\s*\(\s*["\']([^"\']+)["\']\s*\)',
        'range': r'["\']([^"\']+)["\'].+?["\']([^"\']+)["\']',
        'closedRange': r'["\']([^"\']+)["\']\.\.\.["\']\s*([^"\']+)["\']',
        'rangeOperator': r'["\']([^"\']+)["\']\s*\.\.\.?\s*["\']([^"\']+)["\']',
        'branch': r'branch:\s*["\']([^"\']+)["\']',
        'revision': r'revision:\s*["\']([^"\']+)["\']',
    }

    for constraint_type, pattern in version_patterns.items():
        match = re.search(pattern, package_declaration)
        if match:
            if constraint_type == 'from':
                return f"from {match.group(1)}"
            elif constraint_type == 'upToNextMajor':
                version = match.group(1)
                return f"from {version} up to next major (< {int(version.split('.')[0]) + 1}.0.0)"
            elif constraint_type == 'upToNextMinor':
                version = match.group(1)
                parts = version.split('.')
                next_minor = f"{parts[0]}.{int(parts[1]) + 1}.0"
                return f"from {version} up to next minor (< {next_minor})"
            elif constraint_type == 'exact':
                return f"exact {match.group(1)}"
            elif constraint_type in ['range', 'closedRange', 'rangeOperator']:
                if match.lastindex >= 2:
                    return f"range {match.group(1)} ... {match.group(2)}"
            elif constraint_type == 'branch':
                return f"branch: {match.group(1)}"
            elif constraint_type == 'revision':
                return f"revision: {match.group(1)[:8]}..."

    # ê¸°ë³¸ì ì¸ ë²„ì „ ë¬¸ìì—´ ì°¾ê¸°
    version_match = re.search(r'["\'](\d+\.\d+\.\d+[^"\']*)["\']', package_declaration)
    if version_match:
        return f"version {version_match.group(1)}"

    return "ë²„ì „ ì œì•½ ì¡°ê±´ ì—†ìŒ"


def create_directory_path(repo_key, root_repo_key):
    """ë¦¬í¬ì§€í† ë¦¬ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„±"""
    safe_root = root_repo_key.replace('/', '_')
    safe_name = repo_key.replace('/', '_')
    return os.path.join(base_dir, safe_root, safe_name)


def download_package_swift(github_url, root_repo_key, depth=0):
    """Package.swift íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì™„ì „ ì¬ê·€ ë²„ì „)"""
    indent = "  " * min(depth, 10)  # ë„ˆë¬´ ë§ì€ ë“¤ì—¬ì“°ê¸° ë°©ì§€

    try:
        owner, repo = extract_repo_info(github_url)
        if not owner or not repo:
            return False

        repo_key = f"{owner}/{repo}"

        # ì´ë¯¸ ì²˜ë¦¬ëœ ë¦¬í¬ì§€í† ë¦¬ì¸ì§€ í™•ì¸ (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
        if repo_key in processed_repos or repo_key in failed_repos:
            if depth > 0:  # ë£¨íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ìŠ¤í‚µ ë©”ì‹œì§€
                print(f"{indent}ğŸ”„ {repo_key}: ì´ë¯¸ ì²˜ë¦¬ë¨ (ê¹Šì´: {depth})")
            return True

        print(f"{indent}ğŸ” [{len(processed_repos) + 1}] {repo_key} ì²˜ë¦¬ ì¤‘... (ê¹Šì´: {depth})")

        g = get_github_instance()
        repository = g.get_repo(repo_key)

        # ë¸Œëœì¹˜ ì‹œë„
        branches_to_try = []
        default_branch = get_default_branch(repository)
        if default_branch:
            branches_to_try.append(default_branch)

        for branch in ['main', 'master']:
            if branch not in branches_to_try:
                branches_to_try.append(branch)

        package_file = None
        used_branch = None

        for branch in branches_to_try:
            try:
                package_file = repository.get_contents("Package.swift", ref=branch)
                used_branch = branch
                break
            except:
                continue

        if package_file is None:
            failed_repos.add(repo_key)
            print(f"{indent}âŒ {repo_key}: Package.swift ì—†ìŒ")
            return False

        # ë””ë ‰í† ë¦¬ ìƒì„±
        repo_dir = create_directory_path(repo_key, root_repo_key)
        os.makedirs(repo_dir, exist_ok=True)

        # Package.swift íŒŒì¼ ì €ì¥
        package_path = os.path.join(repo_dir, "Package.swift")
        content = package_file.decoded_content.decode('utf-8')

        with open(package_path, 'w', encoding='utf-8') as f:
            f.write(content)

        processed_repos.add(repo_key)
        stats['successful_downloads'] += 1

        print(f"{indent}âœ… {repo_key} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (ë¸Œëœì¹˜: {used_branch})")

        # ì˜ì¡´ì„± ì¶”ì¶œ
        dependencies = extract_dependencies_from_content(content)

        if dependencies:
            stats['dependencies_found'] += len(dependencies)
            if repo_key not in dependency_graph:
                dependency_graph[repo_key] = []

            print(f"{indent}ğŸ“¦ {repo_key}: {len(dependencies)}ê°œ ì˜ì¡´ì„± ë°œê²¬")

            # ì˜ì¡´ì„± ì²˜ë¦¬ (ì™„ì „ ì¬ê·€ - ì œí•œ ì—†ìŒ)
            for i, dep_url in enumerate(dependencies, 1):
                dep_owner, dep_repo = extract_repo_info(dep_url)
                if dep_owner and dep_repo:
                    dep_key = f"{dep_owner}/{dep_repo}"
                    dependency_graph[repo_key].append(dep_key)

                    print(f"{indent}  â””â”€ {i}/{len(dependencies)}: {dep_key}")

                    # ì¬ê·€ í˜¸ì¶œ (ê¹Šì´ ì œí•œ ì—†ìŒ!)
                    download_package_swift(dep_url, root_repo_key, depth + 1)
                    time.sleep(0.2)  # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€ (ë” ë¹ ë¥´ê²Œ)
        else:
            print(f"{indent}ğŸ“¦ {repo_key}: ì˜ì¡´ì„± ì—†ìŒ")

        return True

    except Exception as e:
        if 'repo_key' in locals():
            failed_repos.add(repo_key)
            print(f"{indent}âŒ {repo_key}: {str(e)[:50]}...")
        stats['failed_downloads'] += 1
        return False


def process_all_repositories():
    """CSVì˜ ëª¨ë“  ë¦¬í¬ì§€í† ë¦¬ ì²˜ë¦¬"""
    csv_file = "swift_spm_networking_repos.csv"

    try:
        df = pd.read_csv(csv_file)
    except FileNotFoundError:
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
        return

    stats['total_repos'] = len(df)
    stats['start_time'] = time.time()

    print(f"ğŸš€ ì´ {len(df)}ê°œì˜ ë¦¬í¬ì§€í† ë¦¬ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(base_dir)}")
    print("=" * 80)

    # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ë³€ìˆ˜
    processed_count = 0

    for index, row in df.iterrows():
        processed_count += 1
        github_url = row['url']
        repo_name = row['repo']

        # ì§„í–‰ë¥  í‘œì‹œ
        progress = (processed_count / len(df)) * 100
        print(f"\nğŸ“Š ì§„í–‰ë¥ : {processed_count}/{len(df)} ({progress:.1f}%)")
        print(f"ğŸ” [{processed_count}] {repo_name} ì²˜ë¦¬ ì¤‘...")

        # ë£¨íŠ¸ ë¦¬í¬ì§€í† ë¦¬ë¡œ ì²˜ë¦¬
        owner, repo = extract_repo_info(github_url)
        if owner and repo:
            root_repo_key = f"{owner}/{repo}"
            download_package_swift(github_url, root_repo_key, 0)

        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if processed_count % 10 == 0:
            elapsed = time.time() - stats['start_time']
            avg_time = elapsed / processed_count
            estimated_total = avg_time * len(df)
            remaining = estimated_total - elapsed

            print(f"â±ï¸  ê²½ê³¼ ì‹œê°„: {elapsed / 60:.1f}ë¶„, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining / 60:.1f}ë¶„")
            print(
                f"ğŸ“ˆ í˜„ì¬ ì„±ê³µë¥ : {len(processed_repos)}/{processed_count} ({len(processed_repos) / processed_count * 100:.1f}%)")

        # API ë ˆì´íŠ¸ ë¦¬ë°‹ì„ ìœ„í•œ ëŒ€ê¸°
        time.sleep(0.5)

    stats['end_time'] = time.time()


def create_final_summary():
    """ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    summary_path = os.path.join(base_dir, "FINAL_SUMMARY.md")

    elapsed_time = stats['end_time'] - stats['start_time']

    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("# Swift Package Dependencies - Final Summary\n\n")
        f.write(f"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"**Processing Time**: {elapsed_time / 60:.2f} minutes\n\n")

        f.write("## Statistics\n\n")
        f.write(f"- **Total Repositories in CSV**: {stats['total_repos']}\n")
        f.write(f"- **Successfully Downloaded**: {stats['successful_downloads']}\n")
        f.write(f"- **Failed Downloads**: {stats['failed_downloads']}\n")
        f.write(f"- **Success Rate**: {stats['successful_downloads'] / stats['total_repos'] * 100:.1f}%\n")
        f.write(f"- **Total Dependencies Found**: {stats['dependencies_found']}\n")
        f.write(f"- **Unique Repositories Processed**: {len(processed_repos)}\n\n")

        f.write("## Successfully Processed Repositories\n\n")
        for repo in sorted(processed_repos):
            f.write(f"- {repo}\n")

        if failed_repos:
            f.write(f"\n## Failed Repositories ({len(failed_repos)})\n\n")
            for repo in sorted(failed_repos):
                f.write(f"- {repo}\n")

        f.write("\n## Dependency Relationships\n\n")
        for repo, deps in dependency_graph.items():
            if deps:
                f.write(f"**{repo}**:\n")
                for dep in deps:
                    f.write(f"  - {dep}\n")
                f.write("\n")

    # JSON í˜•íƒœë¡œë„ ì €ì¥
    json_path = os.path.join(base_dir, "dependency_graph.json")
    with open(json_path, 'w') as f:
        json.dump({
            'stats': stats,
            'dependency_graph': dependency_graph,
            'processed_repos': list(processed_repos),
            'failed_repos': list(failed_repos)
        }, f, indent=2)

    print(f"ğŸ“Š ìµœì¢… ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"   ğŸ“„ {summary_path}")
    print(f"   ğŸ“„ {json_path}")


def main():
    print("ğŸŒ Swift Package ì „ì²´ ì˜ì¡´ì„± ë¶„ì„ê¸°")
    print("=" * 50)

    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    if os.path.exists(base_dir) and os.listdir(base_dir):
        print(f"âš ï¸  ê¸°ì¡´ ë°ì´í„°ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤: {base_dir}")
        response = input("ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()

        if response == 'y' or response == 'yes':
            import shutil
            shutil.rmtree(base_dir)
            os.makedirs(base_dir, exist_ok=True)
            print("ğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            print("ğŸ”„ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ëª¨ë“  ë¦¬í¬ì§€í† ë¦¬ ì²˜ë¦¬
    process_all_repositories()

    # ìµœì¢… ìš”ì•½ ìƒì„±
    create_final_summary()

    print("\n" + "=" * 80)
    print("ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬ ì‹œê°„: {(stats['end_time'] - stats['start_time']) / 60:.2f}ë¶„")
    print(f"âœ… ì„±ê³µ: {stats['successful_downloads']}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed_downloads']}ê°œ")
    print(f"ğŸ“ˆ ì„±ê³µë¥ : {stats['successful_downloads'] / stats['total_repos'] * 100:.1f}%")
    print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {os.path.abspath(base_dir)}")


if __name__ == "__main__":
    main()